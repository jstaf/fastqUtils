#!/usr/bin/env python3

import sys
import os
import re
import gzip
import argparse

def main():
    parser = argparse.ArgumentParser(
            description='Re-pair reads from discordant FASTQ files (for instance, after filtering reads by quality).')
    parser.add_argument('-v', '--version', action='version', version='fq-repair version 1.0')
    parser.add_argument('-u', '--keep-unique', default=False, const=True, action='store_const',
            help='Keep reads without a corresponding match. Unique reads are output to a separate file (filename_unique.fastq).')
    parser.add_argument('-1', '--output1', nargs=1, type=str,
            help='Output for first FASTQ file after re-pairing (defaults to "filename_common.fastq"). May be gzipped.')
    parser.add_argument('-2', '--output2', nargs=1, type=str,
            help='Output for second FASTQ file after re-pairing (defaults to "filename_common.fastq"). May be gzipped.')
    parser.add_argument('fastq1', nargs=1, type=str,
            help='First FASTQ file to be re-paired.')
    parser.add_argument('fastq2', nargs=1, type=str,
            help='Second FASTQ file to be re-paired.')
    argv = parser.parse_args()

    fq1 = argv.fastq1
    fq2 = argv.fastq2


class Fastq:
    """
    Helper class to rapidly parse fastq/gz as raw text. 
    (Biopython's Bio.SeqIO.index() does not support gzip compression :'( )
    """

    def __init__(self, filename, mode='r'):
        if not os.path.isfile(filename):
            sys.exit('%s is not a valid file path.' % filename)
        self.filename = filename
        self.mode = mode
        self.handle = self.open()

    
    def __enter__(self):
        pass  # handle is already open

    
    def __exit__(self, typee, value, traceback):
        self.close()

    
    def is_gzip(self):
        return len(re.findall(r'.gz$', self.filename)) > 0


    def open(self):
        """
        Autodetect extension and return filehandle.
        """
        if self.is_gzip():
            self.mode = self.mode + 'b'
            return gzip.open(self.filename, mode=self.mode)
        else:
            return open(self.filename, self.mode)


    def close(self):
        self.handle.close()


    def get_read(self):
        """Get a fastq read. Returns None at EOF"""
        pos = self.handle.tell()
        read = []
        for i in range(4):  # assumes 4-line FASTQ
            line = self.handle.readline()
            if line == '':
                return None  # EOF
            read.append(line)
        return (read, pos)


    def write(self, read):
        self.handle.writelines(read)

    
    def seek(self, position):
        """Jump to a particular file position"""
        self.handle.seek(position)


def index(list_of_fastqs):
    """
    Create a dictionary of readids and their seek positions.
    """
    
    idx = {}
    for filename in list_of_fastqs:
        file_idx = {}
        with Fastq(filename) as fq:
            while True:
                read, pos = fq.get_read()
                if read is None:
                    break
                else:
                    file_idx[read[0]] = pos
        idx[filename] = file_idx
    return idx


def matchReads(fastq1, fastq2):
    idx = index(fastq2)

    # open file handles
    fastq1_common = open(fastq1 + '.common', 'w')
    fastq1_unique = open(fastq1 + '.unique', 'w')
    fastq2_common = open(fastq2 + '.common', 'w')
    fastq1_parser = FASTQParser(fastq1)
    fastq2_parser = FASTQParser(fastq2)
    while True:
        read = fastq1_parser.nextRead()
        # EOF
        if read['quals'] == '':
            break
        ID = regex.findall(read['header'])[0]
        if ID in idxStore.keys():
            # write both reads out to common files, remove key from index
            fastq1_common.writelines([read['header'], read['bases'], read['qheader'], read['quals']])

            fastq2_parser.file.seek(idxStore.pop(ID))
            readMatch = fastq2_parser.nextRead()
            fastq2_common.writelines([readMatch['header'], readMatch['bases'], readMatch['qheader'], readMatch['quals']])
        else:
            # write out to unique file for fastq1
            fastq1_unique.writelines([read['header'], read['bases'], read['qheader'], read['quals']])
    # close file handles
    fastq1_common.close()
    fastq1_unique.close()
    fastq2_common.close()

    # all remaining keys in dictionary are the unique reads for fastq2
    with open(fastq2 + '.unique', 'w') as fastq2_unique:
        for remaining in idxStore:
            fastq2_parser.file.seek(idxStore[remaining])
            read = fastq2_parser.nextRead()
            fastq2_unique.writelines([read['header'], read['bases'], read['qheader'], read['quals']])
    fastq1_parser.close()
    fastq2_parser.close()
    return

if __name__ == '__main__':
    main()

